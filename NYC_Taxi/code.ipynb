{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "415730c7-6a07-459a-a415-ab21b93e194d",
   "metadata": {},
   "source": [
    "## Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83239d7e-c365-4023-89de-106ed7ee6347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Taxi Data\n",
    "# https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf\n",
    "folder_path = \"data/\"\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.parquet')]\n",
    "dataframes = []\n",
    "\n",
    "for f in files:\n",
    "    df = pd.read_parquet(folder_path + f, engine='pyarrow')\n",
    "    dataframes.append(df)\n",
    "\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "df = df.dropna()\n",
    "\n",
    "# Borough Data\n",
    "zones = pd.read_csv('taxi_zone_lookup.csv')\n",
    "zones = zones.fillna('Others')\n",
    "\n",
    "zone_columns = []\n",
    "for z in zones['Borough'].unique():\n",
    "    z_col = 'is_' + (str(z).lower()).replace(' ','')\n",
    "    zone_columns.append(pd.Series(zones[\"Borough\"] == z, name=z_col))\n",
    "\n",
    "zones = pd.concat([zones] + zone_columns, axis=1)\n",
    "zones = zones.drop(['service_zone'], axis=1)\n",
    "zones = zones.rename(columns={'LocationID': 'PULocationID'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54631d5d-a8f8-4eaa-9c14-4e611bc0b14e",
   "metadata": {},
   "source": [
    "## Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e923c16-1100-41ed-ad26-5d62e035463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Engineering\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Travel Time\n",
    "df['travel_time'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).astype('int64') // 60_000_000_000\n",
    "\n",
    "# DateTime to Numeric\n",
    "df['pickup_month'] = df['tpep_pickup_datetime'].dt.month\n",
    "df['pickup_day'] = df['tpep_pickup_datetime'].dt.day\n",
    "df['pickup_hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "df['pickup_minute'] = df['tpep_pickup_datetime'].dt.minute\n",
    "df['pickup_second'] = df['tpep_pickup_datetime'].dt.second\n",
    "\n",
    "# Month Factors\n",
    "for h in range(len(df['pickup_month'].unique())):\n",
    "    df['month_'+str(h)] = (h==df['pickup_month'])\n",
    "    \n",
    "# Time Factors\n",
    "for h in range(len(df['pickup_hour'].unique())):\n",
    "    df['hour_'+str(h)] = (h==df['pickup_hour'])\n",
    "\n",
    "# Location Factors\n",
    "df = pd.merge(df, zones, on='PULocationID', how='left')\n",
    "\n",
    "# Hourly Pickup Rates (Predictor)\n",
    "df['tpep_pickup_date'] = df['tpep_pickup_datetime'].dt.date\n",
    "df['tpep_pickup_hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "hourly_pickup_rates = df.groupby(['Borough', 'tpep_pickup_date', 'tpep_pickup_hour']).size().reset_index(name='hourly_pickup_count')\n",
    "df = df.merge(hourly_pickup_rates, on=['Borough', 'tpep_pickup_date', 'tpep_pickup_hour'], how='left')\n",
    "\n",
    "# Drop Non-Numerics\n",
    "for c in ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'store_and_fwd_flag', 'Borough', 'Zone', 'tpep_pickup_date', 'tpep_pickup_hour']:\n",
    "    if c in df:\n",
    "        del df[c]\n",
    "\n",
    "# Normalizing Data\n",
    "x = df.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "df = min_max_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3024646c-60ef-4569-8261-9689d770be0b",
   "metadata": {},
   "source": [
    "## Test-Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c567ba9-57fc-4c15-9e18-f3e28b11ff21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)  # 70% train\n",
    "train_x, train_y = train_df[:,:-1], train_df[:,-1]\n",
    "test_x, test_y = test_df[:,:-1], test_df[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be024b2-01b9-46a4-b24f-2fc10fd7c0ce",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f92af-15b5-48db-93c9-c0555c6dfeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time \n",
    "\n",
    "start = time.time()\n",
    "regr = SGDRegressor(max_iter=500, tol=0.0001, penalty=None, learning_rate='invscaling', eta0=0.005, n_iter_no_change=5)\n",
    "regr.fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print(\"Train Time:\", end - start)\n",
    "\n",
    "# R^2\n",
    "start = time.time()\n",
    "print(\"R^2:\", r2_score(regr.predict(train_x), train_y),\n",
    "     r2_score(regr.predict(test_x), test_y))\n",
    "\n",
    "# MSE\n",
    "print(\"MSE:\", mean_squared_error(regr.predict(train_x), train_y),\n",
    "     mean_squared_error(regr.predict(test_x), test_y))\n",
    "end = time.time()\n",
    "print(\"Test Time:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2276d4e2-6c3f-4f28-84d5-0e570893b903",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e7b43a-5a3d-4486-a2a2-bd971670d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "start = time.time()\n",
    "regr = SGDRegressor(alpha=0.0001, max_iter=500, tol=0.0001, penalty='l2', learning_rate='invscaling', eta0=0.005, n_iter_no_change=5)\n",
    "regr.fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print(\"Train Time:\", end - start)\n",
    "\n",
    "# R^2\n",
    "start = time.time()\n",
    "print(\"R^2:\", r2_score(regr.predict(train_x), train_y),\n",
    "     r2_score(regr.predict(test_x), test_y))\n",
    "\n",
    "# MSE\n",
    "print(\"MSE:\", mean_squared_error(regr.predict(train_x), train_y),\n",
    "     mean_squared_error(regr.predict(test_x), test_y))\n",
    "end = time.time()\n",
    "print(\"Test Time:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba274ca3-6e1c-4738-be62-7bcab9dd57ce",
   "metadata": {},
   "source": [
    "## L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ba583f-e459-4035-8e3e-b482127fcfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "start = time.time()\n",
    "regr = SGDRegressor(alpha=0.0001, max_iter=500, tol=0.0001, penalty='l1', learning_rate='invscaling', eta0=0.005, n_iter_no_change=5)\n",
    "regr.fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print(\"Train Time:\", end - start)\n",
    "\n",
    "# R^2\n",
    "start = time.time()\n",
    "print(\"R^2:\", r2_score(regr.predict(train_x), train_y),\n",
    "     r2_score(regr.predict(test_x), test_y))\n",
    "\n",
    "# MSE\n",
    "print(\"MSE:\", mean_squared_error(regr.predict(train_x), train_y),\n",
    "     mean_squared_error(regr.predict(test_x), test_y))\n",
    "end = time.time()\n",
    "print(\"Test Time:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352ea42b-a417-4bc5-954e-18da46fca9c2",
   "metadata": {},
   "source": [
    "## ElasticNet (L1 + L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e85098-1a34-4e9c-910a-e59ed8ed511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "start = time.time()\n",
    "regr = SGDRegressor(alpha=0.0001, max_iter=500, tol=0.0001, penalty='elasticnet', l1_ratio=0.5, learning_rate='invscaling', eta0=0.005, n_iter_no_change=5)\n",
    "regr.fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print(\"Train Time:\", end - start)\n",
    "\n",
    "# R^2\n",
    "start = time.time()\n",
    "print(\"R^2:\", r2_score(regr.predict(train_x), train_y),\n",
    "     r2_score(regr.predict(test_x), test_y))\n",
    "\n",
    "# MSE\n",
    "print(\"MSE:\", mean_squared_error(regr.predict(train_x), train_y),\n",
    "     mean_squared_error(regr.predict(test_x), test_y))\n",
    "end = time.time()\n",
    "print(\"Test Time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e51266-7b51-40d2-b2e1-62a356474721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
